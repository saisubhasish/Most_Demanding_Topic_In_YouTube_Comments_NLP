{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0e328cf",
   "metadata": {},
   "source": [
    "# Q-1. \n",
    "Take any YouTube videos link and your task is to extract the comments from\n",
    "that videos and store it in a csv file and then you need define what is most\n",
    "demanding topic in that videos comment section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500bda27",
   "metadata": {},
   "source": [
    "### Let's Scrap the comments from a youtube video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c135a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a8249961",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sai\\AppData\\Local\\Temp\\ipykernel_13112\\133527295.py:13: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(driver_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And, could you also put up some material on how Hidden Markov Models are used in NLP? have studied them way back in 2011 during my Master's degree in the pre Deep Learning era. But don't have much practical exposure to NLP? And does acoustic model for phonemes recognition come more under speech Recognition? Could you also provide a short description on that?\n",
      "HI sir ,thanks for sharing your knowledge it really helps me alot sometime, i have a question. \n",
      "if LSTM has problem , why cant we directly use bidirectional LSTM instead of LSTM , can we skip LSTM and directly apply Bidirectional LSTM ?\n",
      "i love how you spelling it, if we could build such a pyramid for other techs, life of the learners would be much easier as it s enough to keep in mind this intuitive/organic scale of complexity.\n",
      "I just love how you keep reassuring us in the video that you got us covered from bottom to top. This is super helpful. Thank you\n",
      "At 13:00 you had mentioned about weakness of LSTM. If we take the use case of Statistical Machine Translation and I have 2 sentences in my training set :\n",
      "1) \"I cross the river bank to reach primary school\"\n",
      "2) \"I need to go to the bank to urgently withdraw funds\"\n",
      "Both are longish sentences. And if after conversion to Vector Representation, the word \"Bank\" has a different meaning in sentence 1) where we need to look at previous word river, while in sentence 2) we need to look ahead (right context).\n",
      "Is this the issue with plain LSTM that Bidirectional LSTM is able to overcome?\n",
      "Can you please guide me on learning NLP with R, I guess most of the libraries mentioned are python based.  I am not sure if these libraries can also be used in R language as well - Please advise. Thanks\n",
      "Sir, will we be able to do text analytics and sentimental analysis after watching this playlist?\n",
      "I think anyone who is in nlp has eventually followed this kind of roadmap even though the order may be a bit different.\n",
      "i come across with all these concepts in my organisation but its hard me to working on question and answering using tensorflow  or pytorch but i am aware of rasa core n rasa nlu where it is easy to generate question and answers. krish why dont you make a video on question and answering using tensorflow\n",
      "Great Sir, Big fan of yours.  Thanks a lot for detailed course.  Hats off.\n",
      "Hello Sir I have been following you and have currently completed your Machine Learning playlist. So can you tell me that how much prior knowledge we need to have to start with this course, do we need deep learning, if it is so then please tell me do I need advance deep learning like Boltzmann Machine, Autoencoders, GANs and etc or is it okay to start now.\n",
      "Have you ever used spacy when it comes to NLP? If yes: Would be lovely if you could cover how you used it...Thanks for your work\n",
      "Can you please do the video on unstructured text to ontology using NLP. Thanks\n",
      "He is that teacher which our education system genuinely needs . He's self taught hence that is visible in his lectures. Absolutely amazing !!\n",
      "If I need to cover NLP, is this playlist suffix or I need to refer to deep learning playlist also?\n",
      "It  was really helpful. Can u make  videos on Grammer Correction using  Rule based methord, Language Models &  classifiers.\n",
      "its really hard to understand it otherwise\n",
      "This is really a gem\n",
      "Thanks for this wonderful NLP content\n",
      "I just can't thank you enough, words would not be able to compensate for your greatness !\n",
      "Sir I am following this playlist but I am stuck in between because I am not familier with ML,DL so I want to know the important topics of ML,DL which are using in NLP so I will learn only those topics otherwise the whole syllabus of ML,DL will takes too much time , please tell me sir what you prefer to me.?\n",
      "                                                    0\n",
      "0   And, could you also put up some material on ho...\n",
      "1   HI sir ,thanks for sharing your knowledge it r...\n",
      "2   i love how you spelling it, if we could build ...\n",
      "3   I just love how you keep reassuring us in the ...\n",
      "4   At 13:00 you had mentioned about weakness of L...\n",
      "5   Can you please guide me on learning NLP with R...\n",
      "6   Sir, will we be able to do text analytics and ...\n",
      "7   I think anyone who is in nlp has eventually fo...\n",
      "8   i come across with all these concepts in my or...\n",
      "9   Great Sir, Big fan of yours.  Thanks a lot for...\n",
      "10  Hello Sir I have been following you and have c...\n",
      "11  Have you ever used spacy when it comes to NLP?...\n",
      "12  Can you please do the video on unstructured te...\n",
      "13  He is that teacher which our education system ...\n",
      "14  If I need to cover NLP, is this playlist suffi...\n",
      "15  It  was really helpful. Can u make  videos on ...\n",
      "16                               This is really a gem\n",
      "17              Thanks for this wonderful NLP content\n",
      "18  I just can't thank you enough, words would not...\n",
      "19  Sir I am following this playlist but I am stuc...\n"
     ]
    }
   ],
   "source": [
    "# Scrapper code \n",
    "\n",
    "class Data_scraper:\n",
    "    @staticmethod\n",
    "    def scraper(link, path):\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        driver_path = f\"{path}\\selenium\\chromedriver.exe\"\n",
    "        \n",
    "        try:\n",
    "            # Creating a session and loading the page\n",
    "            driver = webdriver.Chrome(driver_path)\n",
    "            driver.get(link)\n",
    "\n",
    "        except Exception as e:\n",
    "            raise InvestmentPredictionException(e, sys)\n",
    "            \n",
    "        # Maximizing window\n",
    "        driver.maximize_window()\n",
    "        # wait time\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Scrolling page to view comments\n",
    "        driver.execute_script(\"window.scrollBy(0,500)\",\"\")\n",
    "        time.sleep(3)\n",
    "        \n",
    "        driver.execute_script(\"window.scrollBy(0,2000)\",\"\")\n",
    "        time.sleep(3)\n",
    "        \n",
    "        driver.execute_script(\"window.scrollBy(0,5000)\",\"\")\n",
    "        time.sleep(3)\n",
    "        \n",
    "        driver.execute_script(\"window.scrollBy(0,5000)\",\"\")\n",
    "        time.sleep(3)\n",
    "        \n",
    "        driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "        \n",
    "        driver.execute_script(\"window.scrollBy(0,2000)\",\"\")\n",
    "        time.sleep(5)\n",
    "        \n",
    "        try:\n",
    "            soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "            # Find the comment sections\n",
    "            # Getting all the comments with web elements\n",
    "            comment_sections = soup.find_all(\"yt-formatted-string\", class_=\"style-scope ytd-comment-renderer\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "        # Extract the comments\n",
    "        # Removing the web elements\n",
    "        comments = [comment.text.strip() for comment in comment_sections]\n",
    "        \n",
    "        # Saving the list of comments to a pandas dataframe\n",
    "        df = pd.DataFrame(comments)\n",
    "        \n",
    "        \n",
    "        # Printing each comment\n",
    "        for comment in comments:\n",
    "            print(comment)\n",
    "            \n",
    "            \n",
    "        print(df)\n",
    "        df.to_csv(f'{path}youtube_comments_scrapped.csv')\n",
    "\n",
    "        # Cloding driver\n",
    "        driver.quit()\n",
    "            \n",
    "link = 'https://www.youtube.com/watch?v=fM4qTMfCoak&list=PLZoTAELRMXVMdJ5sqbCK2LiM0HhQVWNzm'\n",
    "path = 'D:/FSDS-iNeuron/10.Projects-DS//YouTube_Comments/'\n",
    "\n",
    "Data_scraper.scraper(link, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4205bec4",
   "metadata": {},
   "source": [
    "### Lets analyse the data to find the most demanding topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fed5fd88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>And, could you also put up some material on ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>HI sir ,thanks for sharing your knowledge it r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>i love how you spelling it, if we could build ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I just love how you keep reassuring us in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>At 13:00 you had mentioned about weakness of L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Can you please guide me on learning NLP with R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Sir, will we be able to do text analytics and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>I think anyone who is in nlp has eventually fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>i come across with all these concepts in my or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Great Sir, Big fan of yours.  Thanks a lot for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Hello Sir I have been following you and have c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Have you ever used spacy when it comes to NLP?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Can you please do the video on unstructured te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>He is that teacher which our education system ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>If I need to cover NLP, is this playlist suffi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>It  was really helpful. Can u make  videos on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>This is really a gem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Thanks for this wonderful NLP content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>I just can't thank you enough, words would not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>Sir I am following this playlist but I am stuc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                                  0\n",
       "0            0  And, could you also put up some material on ho...\n",
       "1            1  HI sir ,thanks for sharing your knowledge it r...\n",
       "2            2  i love how you spelling it, if we could build ...\n",
       "3            3  I just love how you keep reassuring us in the ...\n",
       "4            4  At 13:00 you had mentioned about weakness of L...\n",
       "5            5  Can you please guide me on learning NLP with R...\n",
       "6            6  Sir, will we be able to do text analytics and ...\n",
       "7            7  I think anyone who is in nlp has eventually fo...\n",
       "8            8  i come across with all these concepts in my or...\n",
       "9            9  Great Sir, Big fan of yours.  Thanks a lot for...\n",
       "10          10  Hello Sir I have been following you and have c...\n",
       "11          11  Have you ever used spacy when it comes to NLP?...\n",
       "12          12  Can you please do the video on unstructured te...\n",
       "13          13  He is that teacher which our education system ...\n",
       "14          14  If I need to cover NLP, is this playlist suffi...\n",
       "15          15  It  was really helpful. Can u make  videos on ...\n",
       "16          16                               This is really a gem\n",
       "17          17              Thanks for this wonderful NLP content\n",
       "18          18  I just can't thank you enough, words would not...\n",
       "19          19  Sir I am following this playlist but I am stuc..."
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = f'{path}youtube_comments_scrapped.csv'\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8622bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6689439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
