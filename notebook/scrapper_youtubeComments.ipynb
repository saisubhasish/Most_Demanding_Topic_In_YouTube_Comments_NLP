{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0e328cf",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "Take any YouTube videos link and your task is to extract the comments from\n",
    "that videos and store it in a csv file and then you need define what is most\n",
    "demanding topic in that videos comment section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500bda27",
   "metadata": {},
   "source": [
    "### Let's Scrap the comments from a youtube video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c135a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8249961",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sai\\AppData\\Local\\Temp\\ipykernel_12620\\1410142067.py:19: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(driver_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I just love how you keep reassuring us in the video that you got us covered from bottom to top. This is super helpful. Thank you\n",
      "He is that teacher which our education system genuinely needs . He's self taught hence that is visible in his lectures. Absolutely amazing !!\n",
      "And, could you also put up some material on how Hidden Markov Models are used in NLP? have studied them way back in 2011 during my Master's degree in the pre Deep Learning era. But don't have much practical exposure to NLP? And does acoustic model for phonemes recognition come more under speech Recognition? Could you also provide a short description on that?\n",
      "HI sir ,thanks for sharing your knowledge it really helps me alot sometime, i have a question. \n",
      "if LSTM has problem , why cant we directly use bidirectional LSTM instead of LSTM , can we skip LSTM and directly apply Bidirectional LSTM ?\n",
      "i love how you spelling it, if we could build such a pyramid for other techs, life of the learners would be much easier as it s enough to keep in mind this intuitive/organic scale of complexity.\n",
      "I just can't thank you enough, words would not be able to compensate for your greatness !\n",
      "At 13:00 you had mentioned about weakness of LSTM. If we take the use case of Statistical Machine Translation and I have 2 sentences in my training set :\n",
      "1) \"I cross the river bank to reach primary school\"\n",
      "2) \"I need to go to the bank to urgently withdraw funds\"\n",
      "Both are longish sentences. And if after conversion to Vector Representation, the word \"Bank\" has a different meaning in sentence 1) where we need to look at previous word river, while in sentence 2) we need to look ahead (right context).\n",
      "Is this the issue with plain LSTM that Bidirectional LSTM is able to overcome?\n",
      "Have you ever used spacy when it comes to NLP? If yes: Would be lovely if you could cover how you used it...Thanks for your work\n",
      "Great work for humanity.. thanks krish.. hats off to you for such efforts\n",
      "Can you please guide me on learning NLP with R, I guess most of the libraries mentioned are python based.  I am not sure if these libraries can also be used in R language as well - Please advise. Thanks\n",
      "Sir, will we be able to do text analytics and sentimental analysis after watching this playlist?\n",
      "It  was really helpful. Can u make  videos on Grammer Correction using  Rule based methord, Language Models &  classifiers.\n",
      "its really hard to understand it otherwise\n",
      "I have done several nlp tasks and out of all what I have felt is , unsupervised text categorization , like classifying them based on topic is what I felt difficult especially if problem becomes multilabel\n",
      "I think anyone who is in nlp has eventually followed this kind of roadmap even though the order may be a bit different.\n",
      "Great Sir, Big fan of yours.  Thanks a lot for detailed course.  Hats off.\n",
      "Hi Sir , Can we Directly learn Transformers and BERT ? because u mentioned that the ones before are having some minor problems\n",
      "i come across with all these concepts in my organisation but its hard me to working on question and answering using tensorflow  or pytorch but i am aware of rasa core n rasa nlu where it is easy to generate question and answers. krish why dont you make a video on question and answering using tensorflow\n",
      "This is really a gem\n",
      "Hello Sir I have been following you and have currently completed your Machine Learning playlist. So can you tell me that how much prior knowledge we need to have to start with this course, do we need deep learning, if it is so then please tell me do I need advance deep learning like Boltzmann Machine, Autoencoders, GANs and etc or is it okay to start now.\n",
      "Hi krish, Can you please do video on mutual funds project like sentiment analysis or recommendations. It will helpful alot.\n",
      "                                                    0\n",
      "0   I just love how you keep reassuring us in the ...\n",
      "1   He is that teacher which our education system ...\n",
      "2   And, could you also put up some material on ho...\n",
      "3   HI sir ,thanks for sharing your knowledge it r...\n",
      "4   i love how you spelling it, if we could build ...\n",
      "5   I just can't thank you enough, words would not...\n",
      "6   At 13:00 you had mentioned about weakness of L...\n",
      "7   Have you ever used spacy when it comes to NLP?...\n",
      "8   Great work for humanity.. thanks krish.. hats ...\n",
      "9   Can you please guide me on learning NLP with R...\n",
      "10  Sir, will we be able to do text analytics and ...\n",
      "11  It  was really helpful. Can u make  videos on ...\n",
      "12  I have done several nlp tasks and out of all w...\n",
      "13  I think anyone who is in nlp has eventually fo...\n",
      "14  Great Sir, Big fan of yours.  Thanks a lot for...\n",
      "15  Hi Sir , Can we Directly learn Transformers an...\n",
      "16  i come across with all these concepts in my or...\n",
      "17                               This is really a gem\n",
      "18  Hello Sir I have been following you and have c...\n",
      "19  Hi krish, Can you please do video on mutual fu...\n"
     ]
    }
   ],
   "source": [
    "# Scrapper code \n",
    "\n",
    "class Data_scraper:\n",
    "    @staticmethod\n",
    "    def scraper(link, path):\n",
    "        \"\"\"\n",
    "        Description: This function scraps comments from youtube videos and stores it to a csv file\n",
    "        =========================================================\n",
    "        Params:\n",
    "        link: link of the video\n",
    "        path: path where file get saved\n",
    "        =========================================================\n",
    "        saves data to a csv file\n",
    "        \"\"\"\n",
    "        driver_path = f\"{path}\\selenium_driver\\chromedriver.exe\"\n",
    "        \n",
    "        try:\n",
    "            # Creating a session and loading the page\n",
    "            driver = webdriver.Chrome(driver_path)\n",
    "            driver.get(link)\n",
    "\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "            \n",
    "        # Maximizing window\n",
    "        driver.maximize_window()\n",
    "        # wait time\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Scrolling page to view comments\n",
    "        driver.execute_script(\"window.scrollBy(0,500)\",\"\")\n",
    "        time.sleep(3)\n",
    "        \n",
    "        driver.execute_script(\"window.scrollBy(0,2000)\",\"\")\n",
    "        time.sleep(3)\n",
    "        \n",
    "        driver.execute_script(\"window.scrollBy(0,5000)\",\"\")\n",
    "        time.sleep(3)\n",
    "        \n",
    "        driver.execute_script(\"window.scrollBy(0,5000)\",\"\")\n",
    "        time.sleep(3)\n",
    "        \n",
    "        driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "        \n",
    "        driver.execute_script(\"window.scrollBy(0,2000)\",\"\")\n",
    "        time.sleep(5)\n",
    "        \n",
    "        try:\n",
    "            soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "            # Find the comment sections\n",
    "            # Getting all the comments with web elements\n",
    "            comment_sections = soup.find_all(\"yt-formatted-string\", class_=\"style-scope ytd-comment-renderer\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "        # Extract the comments\n",
    "        # Removing the web elements\n",
    "        comments = [comment.text.strip() for comment in comment_sections]\n",
    "        \n",
    "        # Saving the list of comments to a pandas dataframe\n",
    "        df = pd.DataFrame(comments)\n",
    "        \n",
    "        \n",
    "        # Printing each comment\n",
    "        for comment in comments:\n",
    "            print(comment)\n",
    "            \n",
    "            \n",
    "        print(df)\n",
    "        df.to_csv(f'{path}youtube_comments_scrapped.csv')\n",
    "\n",
    "        # Cloding driver\n",
    "        driver.quit()\n",
    "            \n",
    "link = 'https://www.youtube.com/watch?v=fM4qTMfCoak&list=PLZoTAELRMXVMdJ5sqbCK2LiM0HhQVWNzm'\n",
    "path = 'D:/FSDS-iNeuron/10.Projects-DS/Most_Demanding_Topic_In_YouTube_Comment_NLP/'\n",
    "\n",
    "Data_scraper.scraper(link, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4205bec4",
   "metadata": {},
   "source": [
    "### Lets analyse the data to find the most demanding topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fed5fd88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I just love how you keep reassuring us in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>He is that teacher which our education system ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>And, could you also put up some material on ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>HI sir ,thanks for sharing your knowledge it r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>i love how you spelling it, if we could build ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>I just can't thank you enough, words would not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>At 13:00 you had mentioned about weakness of L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Have you ever used spacy when it comes to NLP?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Great work for humanity.. thanks krish.. hats ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Can you please guide me on learning NLP with R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Sir, will we be able to do text analytics and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>It  was really helpful. Can u make  videos on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>I have done several nlp tasks and out of all w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>I think anyone who is in nlp has eventually fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Great Sir, Big fan of yours.  Thanks a lot for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Hi Sir , Can we Directly learn Transformers an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>i come across with all these concepts in my or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>This is really a gem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>Hello Sir I have been following you and have c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>Hi krish, Can you please do video on mutual fu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                                  0\n",
       "0            0  I just love how you keep reassuring us in the ...\n",
       "1            1  He is that teacher which our education system ...\n",
       "2            2  And, could you also put up some material on ho...\n",
       "3            3  HI sir ,thanks for sharing your knowledge it r...\n",
       "4            4  i love how you spelling it, if we could build ...\n",
       "5            5  I just can't thank you enough, words would not...\n",
       "6            6  At 13:00 you had mentioned about weakness of L...\n",
       "7            7  Have you ever used spacy when it comes to NLP?...\n",
       "8            8  Great work for humanity.. thanks krish.. hats ...\n",
       "9            9  Can you please guide me on learning NLP with R...\n",
       "10          10  Sir, will we be able to do text analytics and ...\n",
       "11          11  It  was really helpful. Can u make  videos on ...\n",
       "12          12  I have done several nlp tasks and out of all w...\n",
       "13          13  I think anyone who is in nlp has eventually fo...\n",
       "14          14  Great Sir, Big fan of yours.  Thanks a lot for...\n",
       "15          15  Hi Sir , Can we Directly learn Transformers an...\n",
       "16          16  i come across with all these concepts in my or...\n",
       "17          17                               This is really a gem\n",
       "18          18  Hello Sir I have been following you and have c...\n",
       "19          19  Hi krish, Can you please do video on mutual fu..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = f'{path}youtube_comments_scrapped.csv'\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8622bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# resetting index\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "# Converting dataframe to json so that we can dump these record in mongo db\n",
    "json_record = list(json.loads(df.T.to_json()).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6689439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sai\\anaconda3\\lib\\site-packages\\cryptography\\x509\\base.py:562: CryptographyDeprecationWarning: Parsed a negative serial number, which is disallowed by RFC 5280.\n",
      "  return rust_x509.load_der_x509_certificate(data)\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "\n",
    "MONGO_DB_URL = \"mongodb+srv://MongoDB:mongodb123@cluster0.i7o85x8.mongodb.net/?retryWrites=true&w=majority\"\n",
    "mongo_client = pymongo.MongoClient(MONGO_DB_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40fe8e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE_NAME = 'NLP'\n",
    "COLLECTION_NAME = 'youtubeComments'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bff5042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating database\n",
    "mydb = mongo_client[DATABASE_NAME]\n",
    "\n",
    "# Creating collection\n",
    "coll = mydb[COLLECTION_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a139f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x20e98838610>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insert converted json record to mongo db\n",
    "coll.insert_many(json_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1121176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bd13ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
